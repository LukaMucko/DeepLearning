{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning &mdash; Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifth assignment for the 2023 Deep Learning course (NWI-IMC070) of the Radboud University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Names: Luka Mucko, Luca Poli**\n",
    "\n",
    "**Group: 46**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "* Fill in your names and the name of your group.\n",
    "* Answer the questions and complete the code where necessary.\n",
    "* Keep your answers brief, one or two sentences is usually enough.\n",
    "* Re-run the whole notebook before you submit your work.\n",
    "* Save the notebook as a PDF and submit that in Brightspace together with the `.ipynb` notebook file.\n",
    "* The easiest way to make a PDF of your notebook is via File > Print Preview and then use your browser's print option to print to PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this assignment you will\n",
    "1. Construct a PyTorch `DataSet`\n",
    "1. Train and modify a transformer network\n",
    "1. Experiment with a translation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required software\n",
    "\n",
    "If you haven't done so already, you will need to install the following additional libraries:\n",
    "* `torch` for PyTorch,\n",
    "* `d2l`, the library that comes with the [Dive into deep learning](https://d2l.ai) book.  \n",
    "  Note: if you get errors, make sure the right version of the d2l library is installed:\n",
    "  `pip install d2l==1.0.0a1.post0`\n",
    "\n",
    "All libraries can be installed with `pip install`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:43.992132Z",
     "end_time": "2023-10-06T16:16:45.542806Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import math\n",
    "from random import Random\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import (IterableDataset, DataLoader)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = d2l.try_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Learning to calculate (5 points)\n",
    "\n",
    "In this assignment we are going to train a neural network to do mathematics.\n",
    "When communicating between humans, mathematics is expressed with words and formulas.\n",
    "The simplest of these are formulas with a numeric answer. For example, we might ask what is `100+50`, to which the answer is `150`.\n",
    "\n",
    "To teach a computer how to do this task, we are going to need a dataset.\n",
    "\n",
    "Below is a function that generates a random formula. Study it, and see if you understand its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.014214Z",
     "end_time": "2023-10-06T16:16:45.542806Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_integer(length: int, signed: bool = True, rng: Random = Random()):\n",
    "    max = math.pow(10, length)\n",
    "    min = -max if signed else 0\n",
    "    return rng.randint(min, max)\n",
    "\n",
    "def random_formula(complexity: int, signed: bool = True, rng: Random = Random()):\n",
    "    \"\"\"\n",
    "    Generate a random formula of the form \"a+b\" or \"a-b\".\n",
    "    complexity is the maximum number of digits in the numbers.\n",
    "    \"\"\"\n",
    "    a = random_integer(complexity, signed, rng)\n",
    "    b = random_integer(complexity, False, rng)\n",
    "    is_addition = not signed or rng.choice([False, True])\n",
    "    if is_addition:\n",
    "        return (f\"{a}+{b}\", str(a + b))\n",
    "    else:\n",
    "        return (f\"{a}-{b}\", str(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.026672Z",
     "end_time": "2023-10-06T16:16:45.542806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('649+864', '1513')"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123456\n",
    "random_formula(3, rng=Random(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `rng` argument allows us to reproduce the same random numbers, which you can verify by running the code below multiple times. But if you change the seed to `None` then the random generator is initialized differently each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.043624Z",
     "end_time": "2023-10-06T16:16:45.574200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649+864 = 1513\n",
      "-940-819 = -1759\n",
      "954-2 = 952\n",
      "-896-274 = -1170\n",
      "-762-954 = -1716\n"
     ]
    }
   ],
   "source": [
    "def random_formulas(complexity, signed, count, seed):\n",
    "    \"\"\"\n",
    "    Iterator that yields the given count of random formulas\n",
    "    \"\"\"\n",
    "    rng = Random(seed)\n",
    "    for i in range(count):\n",
    "        yield random_formula(complexity, signed, rng=rng)\n",
    "\n",
    "for q, a in random_formulas(3, True, 5, seed):\n",
    "    print(f'{q} = {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to treat these expressions as sequences of tokens, where each character is a token. In addition we will need tokens to denote begin-of-sequence and end-of-sequence, as well as padding, for which we will use `'<bos>'`, `'<eos>'`, and `'<pad>'` respectively, as is done in the book.\n",
    "\n",
    "[d2l chapter 9.2](https://d2l.ai/chapter_recurrent-neural-networks/text-sequence.html) includes an example of tokenizing a string, and it also defines a `Vocab` class that handles converting the tokens to numbers.\n",
    "\n",
    "For this dataset we know beforehand what the vocabulary will be.\n",
    "\n",
    "### Creating a vocabulary\n",
    "\n",
    "**(a) What are the tokens in this dataset? Complete the code below.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.075278Z",
     "end_time": "2023-10-06T16:16:45.583381Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: fill in all possible tokens\n",
    "vocab = d2l.Vocab(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-'], reserved_tokens=['<bos>', '<eos>', '<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the vocabulary to double check that it makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.089276Z",
     "end_time": "2023-10-06T16:16:45.583381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16\n",
      "Vocabulary: ['+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<bos>', '<eos>', '<pad>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:', len(vocab))\n",
    "print('Vocabulary:', vocab.idx_to_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the d2l Vocab class includes a `'<unk>'` token, for handling unknown tokens in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to tokenize and encode formula.\n",
    "\n",
    "**(b) Complete the code below.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.136382Z",
     "end_time": "2023-10-06T16:16:45.583381Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_encode(string: str, vocab=vocab) -> List[int]:\n",
    "    # TODO: Tokenize the string and encode using the vocabulary.\n",
    "    #       Include an end-of-string token (but not a begin-of-string token).\n",
    "    return vocab[list(string)] + [vocab['<eos>']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on a random formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.147596Z",
     "end_time": "2023-10-06T16:16:45.583381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question 649+864 and answer 1513\n",
      "are encoded as [8, 6, 11, 0, 10, 8, 6, 13] and [3, 7, 3, 5, 13]\n"
     ]
    }
   ],
   "source": [
    "q, a = random_formula(3, rng=Random(seed))\n",
    "print('The question', q, 'and answer', a)\n",
    "print('are encoded as', tokenize_and_encode(q), 'and', tokenize_and_encode(a))\n",
    "\n",
    "# Check tokenize_and_encode\n",
    "assert ''.join(vocab.to_tokens(tokenize_and_encode(q))) == q + '<eos>'\n",
    "assert len(tokenize_and_encode(q)) == len(q) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and trimming\n",
    "\n",
    "Next, to be able to work with a whole dataset of these encoded sequences, they all need to be the same length.\n",
    "\n",
    "**(c) Implement the function below that pads or trims the encoded token sequence as needed.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Hint: see [d2l section 10.5.3](http://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length) for a very similar function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.164391Z",
     "end_time": "2023-10-06T16:16:45.600478Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_or_trim(tokens: List[int], target_length: int, vocab=vocab):\n",
    "    if len(tokens) < target_length:\n",
    "        return tokens + [vocab['<pad>']] * (target_length - len(tokens))\n",
    "    elif len(tokens) > target_length:\n",
    "        return tokens[:target_length]\n",
    "    else:\n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.179933Z",
     "end_time": "2023-10-06T16:16:45.616121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[8, 6, 11, 0, 10, 8, 6, 13, 14, 14]"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad or trim q to get a sequence of 10 tokens\n",
    "pad_or_trim(tokenize_and_encode(q), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.225472Z",
     "end_time": "2023-10-06T16:16:45.616121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check pad_or_trim\n",
    "assert len(pad_or_trim([1,2,3,4,5],10)) == 10\n",
    "assert len(pad_or_trim(list(range(20)),10)) == 10\n",
    "assert vocab.to_tokens(pad_or_trim([1,2,3,4,5],10)[5:]) == ['<pad>','<pad>','<pad>','<pad>','<pad>'], \\\n",
    "       f\"Incorrect padding tokens, found {vocab.to_tokens(pad_or_trim([1,2,3,4,5],10)[5:])}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating tokens\n",
    "\n",
    "We can use `vocab.to_tokens` to convert the encoded token sequence back to something more readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.243258Z",
     "end_time": "2023-10-06T16:16:45.616121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['6', '4', '9', '+', '8', '6', '4', '<eos>', '<pad>', '<pad>']"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.to_tokens(pad_or_trim(tokenize_and_encode(q), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we define the `decode_tokens` function to convert entire lists or tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:44.287858Z",
     "end_time": "2023-10-06T16:16:45.616121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5' '1' '3' '+' '1' '3' '2' '3' '<eos>' '<pad>']\n",
      " ['4' '1' '2' '+' '4' '2' '<eos>' '<pad>' '<pad>' '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "def decode_tokens(t, vocab=vocab):\n",
    "    # convert a list, tensor, or array of encoded tokens\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        t = t.detach().cpu().numpy()\n",
    "    t = np.asarray(t)\n",
    "    return np.asarray(vocab.to_tokens(list(t.flatten()))).reshape(*t.shape)\n",
    "\n",
    "# convert all tokens at once\n",
    "print(decode_tokens([pad_or_trim(tokenize_and_encode('513+1323'), 10),\n",
    "                     pad_or_trim(tokenize_and_encode('412+42'), 10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset\n",
    "\n",
    "The most convenient way to use a data generating function for training a neural network is to wrap it in a PyTorch `Dataset`. In this case, we will use an [IterableDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset), which can be used as an iterator to walk over the samples in the dataset.\n",
    "\n",
    "**(d) Complete the code below.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:17:49.759309Z",
     "end_time": "2023-10-06T16:17:49.785416Z"
    }
   },
   "outputs": [],
   "source": [
    "class FormulaDataset(IterableDataset):\n",
    "    def __init__(self, complexity, signed, count, seed=None, vocab=vocab):\n",
    "        self.seed = seed\n",
    "        self.complexity = complexity\n",
    "        self.signed = signed\n",
    "        self.count = count\n",
    "        self.vocab = vocab\n",
    "        self.max_question_length = 2 * complexity + 3\n",
    "        self.max_answer_length = complexity + 2\n",
    "\n",
    "        # TODO: Complete the class definition.\n",
    "        #       See the documentation for IterableDataset for examples.\n",
    "        #       Make sure that the values yielded by the iterator are pairs of torch tensors.\n",
    "        #       To create a repeatable dataset, always start with the same random seed.\n",
    "        data = random_formulas(complexity, signed, count, Random(seed))\n",
    "\n",
    "        self.data = [(torch.tensor(pad_or_trim(tokenize_and_encode(q), self.max_question_length, vocab)),\n",
    "                      torch.tensor(pad_or_trim(tokenize_and_encode(a), self.max_answer_length, vocab)))\n",
    "                     for q, a in data]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Define a training set with 10000 formulas and a validation set with 5000 formulas, both with complexity 3.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Note: make sure that the training and validation set are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:17:52.100553Z",
     "end_time": "2023-10-06T16:17:52.472011Z"
    }
   },
   "outputs": [],
   "source": [
    "complexity = 3\n",
    "signed = True\n",
    "# TODO: Your code here.\n",
    "train_data = FormulaDataset(complexity, signed, 10000, 123456)\n",
    "val_data   = FormulaDataset(complexity, signed, 5000, 1234789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we wrap each dataset in a `DataLoader` to create minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:17:59.386825Z",
     "end_time": "2023-10-06T16:17:59.399661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 125\n",
    "data_loaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_data, batch_size=batch_size),\n",
    "    'val':   torch.utils.data.DataLoader(val_data, batch_size=batch_size),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:00.039429Z",
     "end_time": "2023-10-06T16:18:00.169155Z"
    }
   },
   "outputs": [],
   "source": [
    "# The code below checks that the datasets are defined correctly\n",
    "train_loader = data_loaders['train']\n",
    "val_loader = data_loaders['val']\n",
    "\n",
    "from typing import Tuple\n",
    "from typing_extensions import assert_type\n",
    "for (name, loader), expected_size in zip(data_loaders.items(), [10000,5000]):\n",
    "    first_batch = next(iter(loader))\n",
    "    assert len(first_batch) == 2, \\\n",
    "           f\"The {name} dataset should yield (question, answer) pairs when iterated over.\"\n",
    "    assert torch.is_tensor(first_batch[0]), \\\n",
    "           f\"The questions in the {name} dataset should be torch.tensors\"\n",
    "    assert tuple(first_batch[0].shape) == (batch_size, 2*complexity+3), \\\n",
    "           f\"The questions in the {name} dataset should be of size (batch_size, max_question_length), i.e. {batch_size,2*complexity+3}, found {tuple(first_batch[0].shape)}\"\n",
    "    assert first_batch[0].dtype in [torch.int32,torch.int64], \\\n",
    "           f\"The questions in the {name} dataset should be encoded as integers, found {first_batch[0].dtype}\"\n",
    "    assert torch.equal(next(iter(loader))[0], next(iter(loader))[0]), \\\n",
    "           f\"The {name} dataset should be deterministic, it should produce the same data each time\"\n",
    "    assert all([len(batch[0]) == batch_size for batch in iter(loader)]), \\\n",
    "           f\"Batches should all have the right size. Perhaps the batch size does not evenly divide the dataset size?\"\n",
    "    assert sum([len(batch[0]) for batch in iter(loader)]) == expected_size, \\\n",
    "           f\"{name} dataset does not have the right size, expected {expected_size}, found {sum([len(batch[0]) for batch in iter(loader)])}.\"\n",
    "assert not torch.equal(next(iter(train_loader))[0], next(iter(val_loader))[0]), \\\n",
    "       \"The training data and validation data should not be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Transformer inputs (10 points)\n",
    "\n",
    "There is a detailed description of the transformer model in [chapter 11 of the d2l book](http://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html). We will not use most the code from the book, and instead use [PyTorch's built-in Transformer layers](https://pytorch.org/docs/stable/nn.html#transformer-layers).\n",
    "\n",
    "However, some details we still need to implement ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "\n",
    "Training a transformer uses masked self-attention, so we need some masks. Here are two functions that make these masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:05.104112Z",
     "end_time": "2023-10-06T16:18:05.119803Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(size, device=device):\n",
    "    \"\"\"\n",
    "    Mask that indicates that tokens at a position are not allowed to attend to\n",
    "    tokens in subsequent positions.\n",
    "    \"\"\"\n",
    "    mask = (torch.tril(torch.ones((size, size), device=device))) == 0\n",
    "    return mask\n",
    "\n",
    "def generate_padding_mask(tokens, padding_token):\n",
    "    \"\"\"\n",
    "    Mask that indicates which tokens should be ignored because they are padding.\n",
    "    \"\"\"\n",
    "    return tokens == torch.tensor(padding_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Generate a padding mask for a random encoded token string.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Hint: make sure that `tokens` is a torch.tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:06.223953Z",
     "end_time": "2023-10-06T16:18:06.295678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8,  6, 11,  0, 10,  8,  6, 13, 14, 14])\n",
      "['6' '4' '9' '+' '8' '6' '4' '<eos>' '<pad>' '<pad>']\n",
      "tensor([False, False, False, False, False, False, False, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "q, a = random_formula(3, rng=Random(seed))\n",
    "# TODO: your code here\n",
    "tokens = torch.tensor(pad_or_trim(tokenize_and_encode(q),10))\n",
    "padding_mask = generate_padding_mask(tokens, vocab[\"<pad>\"])\n",
    "print(tokens)\n",
    "print(decode_tokens(tokens))\n",
    "print(padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:07.371210Z",
     "end_time": "2023-10-06T16:18:07.389826Z"
    }
   },
   "outputs": [],
   "source": [
    "# More tests\n",
    "assert list(generate_padding_mask(torch.tensor(pad_or_trim(tokenize_and_encode(\"1+1\"), 8)), vocab['<pad>'])) == [False]*4 + [True]*4, \"Something is wrong with generate_padding_mask\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) How will this mask be used by a transformer?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes the first batch of data from the training set, and it generates a shifted version of the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:09.672201Z",
     "end_time": "2023-10-06T16:18:09.746948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '5' '8' '5' '<eos>']\n",
      " ['2' '4' '4' '<eos>' '<pad>']\n",
      " ['3' '6' '2' '<eos>' '<pad>']\n",
      " ['-' '1' '1' '2' '7']\n",
      " ['2' '2' '7' '<eos>' '<pad>']]\n",
      "[['<bos>' '1' '5' '8' '5']\n",
      " ['<bos>' '2' '4' '4' '<eos>']\n",
      " ['<bos>' '3' '6' '2' '<eos>']\n",
      " ['<bos>' '-' '1' '1' '2']\n",
      " ['<bos>' '2' '2' '7' '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "bos = torch.tensor(vocab['<bos>']).expand(y.shape[0], 1)\n",
    "y_prev = torch.cat((bos, y[:,:-1]), axis=1)\n",
    "\n",
    "# print the first five samples\n",
    "print(decode_tokens(y)[:5])\n",
    "print(decode_tokens(y_prev)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Look at the values for the example above. What is `y_prev` used for during training of a transformer model?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is used during training of a transformer model for autoregressive tasks like language modeling. It serves as the input for the current time step, allowing the model to predict the next token based on the context of the previous tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Why do some rows of `y_prev` end in `'<eos>'`, but not all? Is this a problem?<span style=\"float:right\"> (1 point)</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the varying sequence length. It is not a problem during training transformers are suited for handling sequences of different lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below illustrates what the output of `generate_square_subsequent_mask` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:17.396354Z",
     "end_time": "2023-10-06T16:18:17.415357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "tensor([[False,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "square_subsequent_mask = generate_square_subsequent_mask(y.shape[1])\n",
    "\n",
    "print(square_subsequent_mask.shape)\n",
    "print(square_subsequent_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) How and why should this mask be used? State your answer in terms of `x`,  `y` and/or `y_prev`.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square_subsequent_mask is used when computing self-attention within the transformer model, ensuring that tokens in y or y_prev can attend only to previous tokens and not to future tokens (maintaining causality). It's applied during both training and sequence generation to prevent information from future tokens (e.g., in x or y) from affecting the current token's prediction.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Give an example where it could make sense to use a different mask in a transformer network, instead of the `square_subsequent_mask`?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different mask, allowing bidirectional attention, might be used in tasks like Named Entity Recognition (NER) where tokens need to consider both past and future context for accurate predictions. The standard square_subsequent_mask enforces unidirectional attention and is not suitable for such tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Our discrete vocabulary is not suitable as the input for a transformer. We need an embedding function to map our input vocabulary to a continuous, high-dimensional space.\n",
    "\n",
    "We will use the `torch.nn.Embedding` class to for this. As you can read in the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding), this class maps each token in our vocabulary to a specific point in embedding space, its embedding vector. We will use this embedding vector as the input features for the next layer of our model.\n",
    "\n",
    "The parameters of the embedding are trainable: the embedding vector of each token is optimized along with the rest of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Define an embedding that maps our vocabulary to a 5-dimensional space.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:19.298096Z",
     "end_time": "2023-10-06T16:18:19.328257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(16, 5)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Your code here.\n",
    "embedding = torch.nn.Embedding(len(vocab), 5)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the embedding to some sequences from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:20.028930Z",
     "end_time": "2023-10-06T16:18:20.043600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9,  6, 10,  0, 10,  5,  9, 13, 14],\n",
      "        [ 4,  2,  2,  0,  6,  6, 13, 14, 14],\n",
      "        [ 1,  8,  4,  3,  0, 11, 10,  5, 13]])\n",
      "tensor([[[-0.2755,  0.4936, -0.9318, -1.0590,  0.0812],\n",
      "         [ 1.5436, -0.1595,  0.0352,  1.0103,  0.9799],\n",
      "         [-0.8741, -2.1326,  0.7724, -0.2040, -0.3866],\n",
      "         [-0.2647, -0.4066, -0.6440, -0.5070, -1.6749],\n",
      "         [-0.8741, -2.1326,  0.7724, -0.2040, -0.3866],\n",
      "         [-0.7338, -0.3684,  1.0965, -0.4789, -0.8615],\n",
      "         [-0.2755,  0.4936, -0.9318, -1.0590,  0.0812],\n",
      "         [-0.3668,  0.7976, -1.0272, -1.4837,  1.2461],\n",
      "         [ 0.8463, -0.1704, -0.4039,  0.8560,  1.8727]],\n",
      "\n",
      "        [[-0.9069,  0.3372,  0.4550,  0.5010,  1.1690],\n",
      "         [ 0.6293,  0.5028,  0.4816,  0.1876, -0.4873],\n",
      "         [ 0.6293,  0.5028,  0.4816,  0.1876, -0.4873],\n",
      "         [-0.2647, -0.4066, -0.6440, -0.5070, -1.6749],\n",
      "         [ 1.5436, -0.1595,  0.0352,  1.0103,  0.9799],\n",
      "         [ 1.5436, -0.1595,  0.0352,  1.0103,  0.9799],\n",
      "         [-0.3668,  0.7976, -1.0272, -1.4837,  1.2461],\n",
      "         [ 0.8463, -0.1704, -0.4039,  0.8560,  1.8727],\n",
      "         [ 0.8463, -0.1704, -0.4039,  0.8560,  1.8727]],\n",
      "\n",
      "        [[-1.4982, -0.6449,  1.1232, -0.0676,  0.5415],\n",
      "         [ 0.3576,  0.8375,  0.9688,  1.1500,  0.6560],\n",
      "         [-0.9069,  0.3372,  0.4550,  0.5010,  1.1690],\n",
      "         [ 0.6652,  0.0159, -0.6983,  0.3036, -0.4671],\n",
      "         [-0.2647, -0.4066, -0.6440, -0.5070, -1.6749],\n",
      "         [ 1.5643, -0.2433,  0.4023,  0.5803,  0.3260],\n",
      "         [-0.8741, -2.1326,  0.7724, -0.2040, -0.3866],\n",
      "         [-0.7338, -0.3684,  1.0965, -0.4789, -0.8615],\n",
      "         [-0.3668,  0.7976, -1.0272, -1.4837,  1.2461]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9, 5])\n"
     ]
    }
   ],
   "source": [
    "# take the first batch\n",
    "x, y = next(iter(train_loader))\n",
    "# take three samples\n",
    "x = x[:3]\n",
    "# print the shapes\n",
    "print(x)\n",
    "print(embedding(x))\n",
    "print(x.shape)\n",
    "print(embedding(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h) Explain the output shape.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding transform each element of x to a 5-d tensor. Since x has shape (3, 9), the output has shape (3, 9, 5), where 3 are the number of training samples, 9 the number of elements in each sample, 5 are the dimension for each element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the embedding vectors, or the dimensionality of the embedding space, does not depend on the number of tokens in our vocabulary. We are free to choose an embedding size that fits our problem.\n",
    "\n",
    "For example, let's try an embedding with 2 dimensions, and plot the initial embedding for the tokens in our vocabulary.\n",
    "\n",
    "**(i) Create an embedding with 2 dimensions and plot the embedding for all tokens.<span style=\"float:right\"> (no points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:18:23.728249Z",
     "end_time": "2023-10-06T16:18:23.914324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"394.423125pt\" height=\"297.190125pt\" viewBox=\"0 0 394.423125 297.190125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-10-06T16:18:23.853993</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 297.190125 \nL 394.423125 297.190125 \nL 394.423125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 273.312 \nL 387.223125 273.312 \nL 387.223125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path id=\"m22e750780f\" d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" style=\"stroke: #1f77b4\"/>\n    </defs>\n    <g clip-path=\"url(#p97f8210404)\">\n     <use xlink:href=\"#m22e750780f\" x=\"200.991591\" y=\"261.216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"160.240417\" y=\"209.243638\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"370.990398\" y=\"227.342187\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"203.710579\" y=\"73.715468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"116.641078\" y=\"131.564728\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"46.335852\" y=\"153.984889\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"185.643404\" y=\"72.929137\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"193.973462\" y=\"187.093121\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"223.154065\" y=\"191.62561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"167.313698\" y=\"234.18675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"126.425917\" y=\"164.769053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"99.217877\" y=\"39.222132\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"177.929215\" y=\"109.90618\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"201.632697\" y=\"129.690018\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"181.373507\" y=\"19.296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#m22e750780f\" x=\"127.542769\" y=\"197.911814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mc4223ba5da\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc4223ba5da\" x=\"49.527134\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −2 -->\n      <g transform=\"translate(42.15604 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mc4223ba5da\" x=\"126.325609\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −1 -->\n      <g transform=\"translate(118.954515 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mc4223ba5da\" x=\"203.124084\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <g transform=\"translate(199.942834 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mc4223ba5da\" x=\"279.922559\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1 -->\n      <g transform=\"translate(276.741309 287.910437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mc4223ba5da\" x=\"356.721034\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2 -->\n      <g transform=\"translate(353.539784 287.910437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path id=\"ma1792521c9\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#ma1792521c9\" x=\"30.103125\" y=\"224.038458\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 227.837677) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#ma1792521c9\" x=\"30.103125\" y=\"169.064387\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 172.863606) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#ma1792521c9\" x=\"30.103125\" y=\"114.090316\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 117.889534) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#ma1792521c9\" x=\"30.103125\" y=\"59.116244\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 62.915463) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 273.312 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 387.223125 273.312 \nL 387.223125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 273.312 \nL 387.223125 273.312 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 387.223125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- + -->\n    <g transform=\"translate(204.06353 261.216) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-2b\" d=\"M 2944 4013 \nL 2944 2272 \nL 4684 2272 \nL 4684 1741 \nL 2944 1741 \nL 2944 0 \nL 2419 0 \nL 2419 1741 \nL 678 1741 \nL 678 2272 \nL 2419 2272 \nL 2419 4013 \nL 2944 4013 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-2b\"/>\n    </g>\n   </g>\n   <g id=\"text_11\">\n    <!-- - -->\n    <g transform=\"translate(163.312356 209.243638) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n    </g>\n   </g>\n   <g id=\"text_12\">\n    <!-- 0 -->\n    <g transform=\"translate(374.062337 227.342187) scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_13\">\n    <!-- 1 -->\n    <g transform=\"translate(206.782518 73.715468) scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n    </g>\n   </g>\n   <g id=\"text_14\">\n    <!-- 2 -->\n    <g transform=\"translate(119.713017 131.564728) scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-32\"/>\n    </g>\n   </g>\n   <g id=\"text_15\">\n    <!-- 3 -->\n    <g transform=\"translate(49.407791 153.984889) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-33\"/>\n    </g>\n   </g>\n   <g id=\"text_16\">\n    <!-- 4 -->\n    <g transform=\"translate(188.715343 72.929137) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-34\"/>\n    </g>\n   </g>\n   <g id=\"text_17\">\n    <!-- 5 -->\n    <g transform=\"translate(197.045401 187.093121) scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-35\"/>\n    </g>\n   </g>\n   <g id=\"text_18\">\n    <!-- 6 -->\n    <g transform=\"translate(226.226004 191.62561) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-36\"/>\n    </g>\n   </g>\n   <g id=\"text_19\">\n    <!-- 7 -->\n    <g transform=\"translate(170.385637 234.18675) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-37\"/>\n    </g>\n   </g>\n   <g id=\"text_20\">\n    <!-- 8 -->\n    <g transform=\"translate(129.497856 164.769053) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-38\"/>\n    </g>\n   </g>\n   <g id=\"text_21\">\n    <!-- 9 -->\n    <g transform=\"translate(102.289816 39.222132) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-39\"/>\n    </g>\n   </g>\n   <g id=\"text_22\">\n    <!-- &lt;bos&gt; -->\n    <g transform=\"translate(181.001154 109.90618) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-3c\" d=\"M 4684 3150 \nL 1459 2003 \nL 4684 863 \nL 4684 294 \nL 678 1747 \nL 678 2266 \nL 4684 3719 \nL 4684 3150 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-3e\" d=\"M 678 3150 \nL 678 3719 \nL 4684 2266 \nL 4684 1747 \nL 678 294 \nL 678 863 \nL 3897 2003 \nL 678 3150 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-3c\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"83.789062\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"147.265625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"208.447266\"/>\n     <use xlink:href=\"#DejaVuSans-3e\" x=\"260.546875\"/>\n    </g>\n   </g>\n   <g id=\"text_23\">\n    <!-- &lt;eos&gt; -->\n    <g transform=\"translate(204.704636 129.690018) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-3c\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"83.789062\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"145.3125\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"206.494141\"/>\n     <use xlink:href=\"#DejaVuSans-3e\" x=\"258.59375\"/>\n    </g>\n   </g>\n   <g id=\"text_24\">\n    <!-- &lt;pad&gt; -->\n    <g transform=\"translate(184.445446 19.296) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-3c\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"83.789062\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"147.265625\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"208.544922\"/>\n     <use xlink:href=\"#DejaVuSans-3e\" x=\"272.021484\"/>\n    </g>\n   </g>\n   <g id=\"text_25\">\n    <!-- &lt;unk&gt; -->\n    <g transform=\"translate(130.614708 197.911814) scale(0.1 -0.1)\">\n     <defs>\n      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-3c\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"83.789062\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"147.167969\"/>\n     <use xlink:href=\"#DejaVuSans-6b\" x=\"210.546875\"/>\n     <use xlink:href=\"#DejaVuSans-3e\" x=\"268.457031\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p97f8210404\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Your code here.\n",
    "embedding = torch.nn.Embedding(len(vocab), 2)\n",
    "\n",
    "# embed all tokens of our vocabulary\n",
    "x = torch.arange(len(vocab))\n",
    "emb = embedding(x).detach().cpu().numpy()\n",
    "\n",
    "plt.scatter(emb[:, 0], emb[:, 1]);\n",
    "for i, token in enumerate(vocab.idx_to_token):\n",
    "    plt.annotate(token, (emb[i,0]+0.04, emb[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we need to balance the complexity of our networks: a larger embedding will increase the number of parameters in our model, but increase the risk of overfitting.\n",
    "\n",
    "**(j) Would this 2-dimensional embedding space be large enough for our problem?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the complexity of our problem, a 2-dimension could work. But we can also use a larger embedding space, 16 for simulate hot encoding, or even larger to improve the model performance.\n",
    "#todo check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using an embedding, we could also use a simple one-hot encoding to map the words in the vocabulary to feature vectors. However, practical applications of natural language processing never do this. Why not?\n",
    "\n",
    "**(k) Explain the practical advantage of embeddings over one-hot encoding.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practical application of NLP they never do that because their vocabulary is too large and the one-hot encoding would be too sparse. The embedding can represent a large vocabulary in a smaller dense vector space, and it can be also trained to represent the similarity between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 `torch.nn.Transformer` (8 points)\n",
    "\n",
    "<div style=\"float: left\"><a href=\"https://cs.ru.nl/~gvtulder/vaswani-fig-1-highlight.png\"><img src=\"https://cs.ru.nl/~gvtulder/vaswani-fig-1-highlight.png\" width=\"300\"></a></div>\n",
    "\n",
    "We now have all required inputs for our transformer.\n",
    "\n",
    "Consult the documentation for the [`torch.nn.Transformer`](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) class of PyTorch. This class implements a full Transformer as described in [\"Attention Is All You Need\"](https://arxiv.org/pdf/1706.03762.pdf), the paper that introduced this architecture.\n",
    "\n",
    "The `Transformer` class implements the main part of the of the Transformer architecture, shown highlighted in the image on the left (see also Fig. 1 in \"Attention Is All You Need\").\n",
    "\n",
    "For a given input sequence, it applies one or more encoder layers, followed by one or more decoder layers, to compute an output sequence that we can then process further.\n",
    "\n",
    "Because the `Transformer` class takes care of most of the complicated parts of the model, we can concentrate providing the inputs and outputs: the grayed-out areas in the image.\n",
    "\n",
    "Check out the parameters for the `Transformer` class and the inputs and outputs of its `forward` function.\n",
    "<br style=\"clear: both\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Which parameter of the `Transformer` class should we base on our embedding?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The parameter of the transform class is the `d_model` parameter, which is the number of expected features, which correspond to the embedding size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(b) Given fixed input and output dimensions, which parameters of the `Transformer` can we use to change the complexity of our network?<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To increase or decrease the complexity we can change the number of encode_layer, decode_layer, the number of heads, the feedforward dimension."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(c) When using the `Transformer` class, where should we use the masks that we defined earlier?<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We should use the masks, previously defined, in the `forward` function. We shuold use the `square_subsequence_mask` in the `tgt_mask` parameter and the `padding_mask` for `src_key_padding_mask`, `memory_key_padding_mask`, `tgt_key_padding_mask` parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(d) Complete the code for the TransformerNetwork.<span style=\"float:right\"> (5 points)</span>**\n",
    "\n",
    "Construct a network with the following architecture (see the image in the previous section for an overview):\n",
    "1. An embedding layer that embeds the input tokens into a space of size `dim_hidden`.\n",
    "2. A dropout layer (not shown in the image).\n",
    "3. A [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) with the specified parameters (`dim_hidden`, `num_heads`, `num_layers`, `dim_feedforward`, and `dropout`).<br>Note: you will need to pass `batch_first=True`, to indicate that the first dimension runs over the batch and not over the sequence.\n",
    "4. A final linear prediction layer that takes the output of the transformer to `dim_vocab` possible classes.\n",
    "\n",
    "Don't worry about positional encoding for now, we will add that later.\n",
    "\n",
    "The `forward` function should generate the appropriate masks and combine the layers defined in `__init__` to compute the output."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "class TransformerNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_vocab=len(vocab), padding_token=vocab['<pad>'],\n",
    "                 num_layers=2, num_heads=4, dim_hidden=64, dim_feedforward=64,\n",
    "                 dropout=0.01, positional_encoding=False):\n",
    "        super().__init__()\n",
    "        self.padding_token = padding_token\n",
    "        # TODO: Your code here.\n",
    "        self.embedding    = torch.nn.Embedding(dim_vocab, dim_hidden)\n",
    "        self.dropout      = torch.nn.Dropout(dropout)\n",
    "        self.transformer  = torch.nn.Transformer(dim_hidden, num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "                                                 dim_feedforward=dim_feedforward, batch_first=True, dropout=dropout)\n",
    "        self.predict      = torch.nn.Linear(dim_hidden, dim_vocab)\n",
    "        if positional_encoding:\n",
    "            self.pos_encoding = ... # Fill this in later\n",
    "        else:\n",
    "            self.pos_encoding = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # TODO: Your code here.\n",
    "        # Combine self.embedding, self.dropout, self.transformer, self.predict\n",
    "        src_padding_mask = generate_padding_mask(src, self.padding_token)\n",
    "        tgt_padding_mask = generate_padding_mask(tgt, self.padding_token)\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt.shape[1], device=tgt.device)\n",
    "\n",
    "        src = self.dropout(self.embedding(src))\n",
    "        tgt = self.dropout(self.embedding(tgt))\n",
    "\n",
    "        out = self.transformer(src, tgt,\n",
    "                               memory_key_padding_mask=src_padding_mask, src_key_padding_mask=src_padding_mask,\n",
    "                               tgt_key_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n",
    "                                # memory_key_padding_mask=generate_padding_mask(src, self.padding_token),\n",
    "                               # src_key_padding_mask=generate_padding_mask(src, self.padding_token),\n",
    "                               # tgt_key_padding_mask=generate_padding_mask(tgt, self.padding_token),\n",
    "                               # tgt_mask=generate_square_subsequent_mask(tgt.shape[1], device=tgt.device))\n",
    "        return self.predict(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:44:34.045763Z",
     "end_time": "2023-10-06T16:44:34.088893Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Try the transformer with an example batch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:44:35.000266Z",
     "end_time": "2023-10-06T16:44:35.092632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([125, 9])\n",
      "y.shape torch.Size([125, 5])\n",
      "y_prev.shape torch.Size([125, 5])\n",
      "y_pred.shape torch.Size([125, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "net = TransformerNetwork(dim_feedforward=72)\n",
    "x, y = next(iter(train_loader))\n",
    "bos = torch.tensor(vocab['<bos>']).expand(y.shape[0], 1)\n",
    "y_prev = torch.cat((bos, y[:, :-1]), axis=1)\n",
    "\n",
    "print('x.shape', x.shape)\n",
    "print('y.shape', y.shape)\n",
    "print('y_prev.shape', y_prev.shape)\n",
    "\n",
    "y_pred = net(x, y_prev)\n",
    "print('y_pred.shape', y_pred.shape)\n",
    "\n",
    "# check the shape against what we expected\n",
    "np.testing.assert_equal(list(y_pred.shape), [y.shape[0], y.shape[1], len(vocab)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert these predictions to tokens (but they're obviously random):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:44:35.911400Z",
     "end_time": "2023-10-06T16:44:35.923432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<unk>' '5' '2' '<bos>' '7']\n",
      " ['<eos>' '4' '5' '5' '1']\n",
      " ['<unk>' '5' '<bos>' '<bos>' '7']\n",
      " ['<unk>' '<bos>' '5' '5' '6']\n",
      " ['<unk>' '<unk>' '<bos>' '<eos>' '<unk>']]\n"
     ]
    }
   ],
   "source": [
    "print(decode_tokens(torch.argmax(y_pred, dim=2))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:44:36.441998Z",
     "end_time": "2023-10-06T16:44:36.681336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check that the transformer is defined correctly\n",
    "assert isinstance(net.embedding, torch.nn.Embedding)\n",
    "assert isinstance(net.dropout, torch.nn.Dropout)\n",
    "assert isinstance(net.transformer, torch.nn.Transformer)\n",
    "assert isinstance(net.predict, torch.nn.Linear)\n",
    "# Check parameters of transformer\n",
    "assert net.transformer.d_model == 64\n",
    "assert net.transformer.nhead == 4\n",
    "assert net.transformer.batch_first == True\n",
    "assert net.transformer.encoder.num_layers == 2\n",
    "assert net.transformer.decoder.num_layers == 2\n",
    "assert net.transformer.encoder.layers[0].linear1.out_features == 72\n",
    "assert net.dropout.p == 0.01\n",
    "assert net.transformer.encoder.layers[0].dropout.p == 0.01\n",
    "# Check that the forward function behaves correctly\n",
    "net.train(False)\n",
    "assert torch.all(torch.isclose( \\\n",
    "            net(x, y_prev), \\\n",
    "            net(torch.cat((x,torch.tensor(vocab['<pad>']).expand(x.shape[0], 5)), axis=1), y_prev), atol=1e-5)), \\\n",
    "       \"Adding padding to x should not affect the output of the network. Check src_key_padding_mask and memory_key_padding_mask. The former controls self attention to padding tokens in the encoder, the latter controls cross attention from decoder to encoder.\"\n",
    "assert torch.all(torch.isclose( \\\n",
    "            net(x, y_prev), \\\n",
    "            net(x, torch.cat((y_prev,torch.tensor(vocab['<pad>']).expand(y.shape[0], 5)), axis=1))[:,:-5], atol=1e-5)), \\\n",
    "       \"Adding padding to y should not affect the output of the network. Check tgt_key_padding_mask.\"\n",
    "assert torch.all(torch.isclose( \\\n",
    "            net(x, y_prev)[:,:2], \\\n",
    "            net(x, y_prev[:,:2]), atol=1e-5)), \\\n",
    "       \"The presence of later tokens in y should not affect the output for earlier tokens. Check tgt_mask.\"\n",
    "assert torch.all(torch.isclose( \\\n",
    "            net(x, y_prev), \\\n",
    "            net(torch.flip(x, [1]), y_prev), atol=1e-5)), \\\n",
    "       \"Order of x should not matter for a transformer network. Check src_mask.\"\n",
    "assert not torch.all(torch.isclose( \\\n",
    "            net(x, torch.flip(y_prev, [1])), \\\n",
    "            torch.flip(net(x, y_prev), [1]), atol=1e-5)), \\\n",
    "       \"Order of y should matter for a transformer network. Check tgt_mask.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Training (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will base the training code on last week's code. A complication in computing the loss and accuracy are the padding tokens. So, before we work on the training loop itself, we need to update the `accuracy` function so it ingores these `<pad>` tokens. Let's do this in a generic way\n",
    "\n",
    "**(a) Copy the `accuracy` function from last week, and add a parameter `ignore_index`. The tokens with `y == ignore_index` should be ignored.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Hint: you can select elements from a tensor with `some_tensor[include]` where `include` is a tensor of booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:00:09.119545Z",
     "end_time": "2023-10-06T16:00:09.147142Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y, ignore_index=None):\n",
    "    # Computes the mean accuracy.\n",
    "    # y_hat: raw network output (before sigmoid or softmax)\n",
    "    #        shape (samples, classes)\n",
    "    # y:     shape (samples)\n",
    "    #ignore_index: ignore tokens equal to ignore_index\n",
    "    ignore_indices = torch.where(y!=ignore_index)\n",
    "    y_hat = y_hat[ignore_indices]\n",
    "    y = y[ignore_indices]\n",
    "    if y_hat.shape[1] == 1:\n",
    "        # binary classification\n",
    "        y_hat = (y_hat[:, 0] > 0).to(y.dtype)\n",
    "    else:\n",
    "        # multi-class classification\n",
    "        y_hat = torch.argmax(y_hat, axis=1).to(y.dtype)\n",
    "    correct = (y_hat == y).to(torch.float32)\n",
    "    return torch.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:00:09.763141Z",
     "end_time": "2023-10-06T16:00:09.852094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test the accuracy function.\n",
    "assert accuracy(torch.tensor([[1,0,0],[0.4,0.5,0.1],[0,1,0],[0.4,0.1,0.5]]), torch.tensor([0,1,2,2]), 1) == 2/3\n",
    "assert accuracy(torch.tensor([[1,0,0],[0.4,0.5,0.1],[0,1,0],[0.4,0.1,0.5]]), torch.tensor([0,1,2,2]), 2) == 1\n",
    "assert accuracy(torch.tensor([[1,0,0],[0.4,0.5,0.1],[0,1,0],[0.4,0.1,0.5]]), torch.tensor([0,1,2,2]), 3) == 3/4\n",
    "assert accuracy(torch.tensor([[1,0,0],[0.4,0.5,0.1],[0,1,0],[0.4,0.1,0.5]]), torch.tensor([2,2,1,2]), 2) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Write a training loop for the transformer model.<span style=\"float:right\"> (4 points)</span>**\n",
    "\n",
    "See last week's assignment for inspiration.\n",
    "The code is mostly the same with the following changes:\n",
    " * The cross-entropy loss function and accuracy should ignore all `<pad>` tokens. (Use `ignore_index`, see the [documentation of CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).)\n",
    " * The network expects `y_prev` as an extra input.\n",
    " * The output of the network contains a batch of N samples, with maximum length L, and gives logits over C classes, so it has size (N,L,C). But `CrossEntropyLoss` and `accuracy` expect a tensor of size (N,C,L). You can use [torch.Tensor.transpose](https://pytorch.org/docs/stable/generated/torch.transpose.html) to change the output to the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:16:56.166926Z",
     "end_time": "2023-10-06T16:16:56.235997Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, data_loaders, epochs=100, lr=0.001, device=device):\n",
    "    \"\"\"\n",
    "    Trains the model net with data from the data_loaders['train'] and data_loaders['val'].\n",
    "    \"\"\"\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    animator = d2l.Animator(xlabel='epoch',\n",
    "                            legend=['train loss', 'train acc', 'validation loss', 'validation acc'],\n",
    "                            figsize=(10, 5))\n",
    "\n",
    "    timer = {'train': d2l.Timer(), 'val': d2l.Timer()}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # monitor loss, accuracy, number of samples\n",
    "        metrics = {'train': d2l.Accumulator(3), 'val': d2l.Accumulator(3)}\n",
    "\n",
    "        for phase in ('train', 'val'):\n",
    "            # switch network to train/eval mode\n",
    "            net.train(phase == 'train')\n",
    "\n",
    "            for i, (x, y) in enumerate(data_loaders[phase]):\n",
    "                timer[phase].start()\n",
    "\n",
    "                # move to device\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                # compute prediction\n",
    "                #NETWORK EXPECTS Y_PREV AS AN EXTRA INPUT\n",
    "                bos = torch.tensor(vocab['<bos>']).expand(y.shape[0], 1)\n",
    "                y_prev = torch.cat((bos, y[:, :-1]), axis=1)\n",
    "                y_hat = net(x, y_prev)\n",
    "\n",
    "                #PERMUTE FROM (N,L,C) to (N,C,L)\n",
    "                y_hat = y_hat.permute(0,2,1)\n",
    "\n",
    "                if y_hat.shape[1] == 1:\n",
    "                    # compute binary cross-entropy loss\n",
    "                    loss = torch.nn.BCEWithLogitsLoss()(y_hat[:, 0], y.to(torch.float))\n",
    "                else:\n",
    "                    # compute cross-entropy loss\n",
    "                    #IGNORE <pad> index 14\n",
    "                    loss = torch.nn.CrossEntropyLoss(ignore_index=vocab.token_to_idx['<pad>'])(y_hat, y)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # compute gradients and update weights\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                metrics[phase].add(loss * x.shape[0],\n",
    "                                   accuracy(y_hat, y, ignore_index=vocab.token_to_idx['<pad>']) * x.shape[0],\n",
    "                                   x.shape[0])\n",
    "\n",
    "                timer[phase].stop()\n",
    "\n",
    "        animator.add(epoch + 1,\n",
    "            (metrics['train'][0] / metrics['train'][2],\n",
    "             metrics['train'][1] / metrics['train'][2],\n",
    "             metrics['val'][0] / metrics['val'][2],\n",
    "             metrics['val'][1] / metrics['val'][2]))\n",
    "\n",
    "    train_loss = metrics['train'][0] / metrics['train'][2]\n",
    "    train_acc  = metrics['train'][1] / metrics['train'][2]\n",
    "    val_loss   = metrics['val'][0] / metrics['val'][2]\n",
    "    val_acc    = metrics['val'][1] / metrics['val'][2]\n",
    "    examples_per_sec = metrics['train'][2] * epochs / timer['train'].sum()\n",
    "\n",
    "    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'val loss {val_loss:.3f}, val acc {val_acc:.3f}')\n",
    "    print(f'{examples_per_sec:.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Train a transformer network. Use 100 epochs with a learning of 0.001<span style=\"float:right\"> (no points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[134], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m net \u001B[38;5;241m=\u001B[39m TransformerNetwork(dim_feedforward\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m72\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[133], line 51\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, data_loaders, epochs, lr, device)\u001B[0m\n\u001B[0;32m     49\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     50\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 51\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m metrics[phase]\u001B[38;5;241m.\u001B[39madd(loss \u001B[38;5;241m*\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     54\u001B[0m                    accuracy(y_hat, y, ignore_index\u001B[38;5;241m=\u001B[39mvocab\u001B[38;5;241m.\u001B[39mtoken_to_idx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<pad>\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m*\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     55\u001B[0m                    x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     57\u001B[0m timer[phase]\u001B[38;5;241m.\u001B[39mstop()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    130\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    133\u001B[0m         group,\n\u001B[0;32m    134\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    139\u001B[0m         state_steps)\n\u001B[1;32m--> 141\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:281\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    279\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 281\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    289\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:391\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    389\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 391\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    393\u001B[0m param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"585.7625pt\" height=\"321.95625pt\" viewBox=\"0 0 585.7625 321.95625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-10-06T16:16:29.444451</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 321.95625 \nL 585.7625 321.95625 \nL 585.7625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 284.4 \nL 578.5625 284.4 \nL 578.5625 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 88.198864 284.4 \nL 88.198864 7.2 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m8627b99857\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8627b99857\" x=\"88.198864\" y=\"284.4\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <g transform=\"translate(85.017614 298.998438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 172.744318 284.4 \nL 172.744318 7.2 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m8627b99857\" x=\"172.744318\" y=\"284.4\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <g transform=\"translate(169.563068 298.998438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 257.289773 284.4 \nL 257.289773 7.2 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m8627b99857\" x=\"257.289773\" y=\"284.4\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <g transform=\"translate(254.108523 298.998438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 341.835227 284.4 \nL 341.835227 7.2 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m8627b99857\" x=\"341.835227\" y=\"284.4\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <g transform=\"translate(338.653977 298.998438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 426.380682 284.4 \nL 426.380682 7.2 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m8627b99857\" x=\"426.380682\" y=\"284.4\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <g transform=\"translate(420.018182 298.998438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 510.926136 284.4 \nL 510.926136 7.2 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m8627b99857\" x=\"510.926136\" y=\"284.4\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12 -->\n      <g transform=\"translate(504.563636 298.998438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(284.334375 312.676562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path d=\"M 20.5625 271.8 \nL 578.5625 271.8 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path id=\"m3f458115de\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"271.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 275.599219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path d=\"M 20.5625 236.936785 \nL 578.5625 236.936785 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"236.936785\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1 -->\n      <g transform=\"translate(7.2 240.736004) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path d=\"M 20.5625 202.07357 \nL 578.5625 202.07357 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"202.07357\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 205.872789) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path d=\"M 20.5625 167.210355 \nL 578.5625 167.210355 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"167.210355\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 3 -->\n      <g transform=\"translate(7.2 171.009574) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path d=\"M 20.5625 132.34714 \nL 578.5625 132.34714 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"132.34714\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 136.146359) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path d=\"M 20.5625 97.483925 \nL 578.5625 97.483925 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"97.483925\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 5 -->\n      <g transform=\"translate(7.2 101.283144) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <path d=\"M 20.5625 62.62071 \nL 578.5625 62.62071 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"62.62071\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 66.419929) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <path d=\"M 20.5625 27.757495 \nL 578.5625 27.757495 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m3f458115de\" x=\"20.5625\" y=\"27.757495\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 7 -->\n      <g transform=\"translate(7.2 31.556714) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 45.926136 264.789782 \nL 88.198864 271.425408 \nL 130.471591 271.616981 \nL 172.744318 271.690174 \nL 215.017045 271.726256 \nL 257.289773 271.746942 \nL 299.5625 271.759906 \nL 341.835227 271.768593 \nL 384.107955 271.774742 \nL 426.380682 271.779262 \nL 468.653409 271.782674 \nL 510.926136 271.785306 \nL 553.198864 271.787397 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 45.926136 265.795857 \nL 88.198864 264.672564 \nL 130.471591 264.600049 \nL 172.744318 264.46478 \nL 215.017045 264.371346 \nL 257.289773 264.243049 \nL 299.5625 264.091046 \nL 341.835227 264.003191 \nL 384.107955 263.923702 \nL 426.380682 263.75357 \nL 468.653409 263.655256 \nL 510.926136 263.673385 \nL 553.198864 263.492096 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 45.926136 104.431067 \nL 88.198864 86.438857 \nL 130.471591 73.805146 \nL 172.744318 64.416931 \nL 215.017045 56.664564 \nL 257.289773 49.869761 \nL 299.5625 44.084442 \nL 341.835227 39.055441 \nL 384.107955 34.924933 \nL 426.380682 30.53707 \nL 468.653409 26.657533 \nL 510.926136 23.160164 \nL 553.198864 19.8 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 45.926136 271.8 \nL 88.198864 271.8 \nL 130.471591 271.8 \nL 172.744318 271.8 \nL 215.017045 271.8 \nL 257.289773 271.8 \nL 299.5625 271.8 \nL 341.835227 271.8 \nL 384.107955 271.8 \nL 426.380682 271.8 \nL 468.653409 271.8 \nL 510.926136 271.8 \nL 553.198864 271.8 \n\" clip-path=\"url(#pc6f156e8ea)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 284.4 \nL 20.5625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 578.5625 284.4 \nL 578.5625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 284.4 \nL 578.5625 284.4 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 578.5625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 467.834375 176.65625 \nL 571.5625 176.65625 \nQ 573.5625 176.65625 573.5625 174.65625 \nL 573.5625 116.94375 \nQ 573.5625 114.94375 571.5625 114.94375 \nL 467.834375 114.94375 \nQ 465.834375 114.94375 465.834375 116.94375 \nL 465.834375 174.65625 \nQ 465.834375 176.65625 467.834375 176.65625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 469.834375 123.042188 \nL 479.834375 123.042188 \nL 489.834375 123.042188 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- train loss -->\n     <g transform=\"translate(497.834375 126.542188) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n     </g>\n    </g>\n    <g id=\"line2d_34\">\n     <path d=\"M 469.834375 137.720313 \nL 479.834375 137.720313 \nL 489.834375 137.720313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_17\">\n     <!-- train acc -->\n     <g transform=\"translate(497.834375 141.220313) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n     </g>\n    </g>\n    <g id=\"line2d_35\">\n     <path d=\"M 469.834375 152.398438 \nL 479.834375 152.398438 \nL 489.834375 152.398438 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- validation loss -->\n     <g transform=\"translate(497.834375 155.898438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"300.78125\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"339.990234\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"367.773438\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"428.955078\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"492.333984\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"524.121094\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"551.904297\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"613.085938\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"665.185547\"/>\n     </g>\n    </g>\n    <g id=\"line2d_36\">\n     <path d=\"M 469.834375 167.076563 \nL 479.834375 167.076563 \nL 489.834375 167.076563 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- validation acc -->\n     <g transform=\"translate(497.834375 170.576563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"300.78125\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"339.990234\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"367.773438\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"428.955078\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"492.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"524.121094\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"585.400391\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"640.380859\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc6f156e8ea\">\n   <rect x=\"20.5625\" y=\"7.2\" width=\"558\" height=\"277.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = TransformerNetwork(dim_feedforward=72)\n",
    "train(net, data_loaders, epochs=100, lr=0.001, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Briefly discuss the results. Has the training converged? Is this a good calculator?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Run the trained network with input `\"123+123\"` and `\"321+321\"`.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, q, a):\n",
    "    # Run net to predict the output given the input `q` and y_prev based on `a`.\n",
    "    # Return predicted y\n",
    "    with torch.no_grad():\n",
    "        # Tokenize and encode the input strings\n",
    "        q_encoded = tokenize_and_encode(q)\n",
    "        a_encoded = tokenize_and_encode(a)\n",
    "\n",
    "        # Convert the encoded tokens to tensors\n",
    "        q_tensor = torch.tensor(pad_or_trim(q_encoded, max_question_length, vocab))\n",
    "        a_tensor = torch.tensor(pad_or_trim(a_encoded, max_answer_length, vocab))\n",
    "\n",
    "        # Move tensors to the device\n",
    "        q_tensor = q_tensor.to(device)\n",
    "        a_tensor = a_tensor.to(device)\n",
    "\n",
    "        # Expand dimensions to add batch size (assuming batch size = 1)\n",
    "        q_tensor = q_tensor.unsqueeze(0)\n",
    "        a_tensor = a_tensor.unsqueeze(0)\n",
    "\n",
    "        # Predict the output\n",
    "        y_pred = net(q_tensor, a_tensor)\n",
    "\n",
    "for src, tgt in [('123+123', '246'), ('321+321', '642')]:\n",
    "    print(f'For {src}={tgt}')\n",
    "    y_pred = predict(net, src, tgt)\n",
    "    print('  y_pred[0]', y_pred[0])\n",
    "    print('  encoded', torch.argmax(y_pred, dim=-1))\n",
    "    print('  tokens', decode_tokens(torch.argmax(y_pred, dim=-1)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Compare the predictions for the first element of y with the two different inputs. Can you explain what happens?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Does the validation accuracy estimate how often the model is able to answers formulas correctly? Explain your answer.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h) If the forward function takes the shifted output `y_prev` as input, how can we use it if we don't know the output yet?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Positional encoding (5 points)\n",
    "\n",
    "We did not yet include positional encoding in the network.\n",
    "PyTorch does not include such an encoder, so here we copied the code from the book (slightly modified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:26:28.498185Z",
     "end_time": "2023-10-06T16:26:28.544878Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, max_len=1000):\n",
    "        super().__init__()\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X + self.P[:, :X.shape[1], :].to(X.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Add positional encoding to the TransformerModel.<span style=\"float:right\"> (point given in earlier question)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-06T16:26:30.093888Z",
     "end_time": "2023-10-06T16:26:30.143556Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: See over there.\n",
    "class TransformerNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_vocab=len(vocab), padding_token=vocab['<pad>'],\n",
    "                 num_layers=2, num_heads=4, dim_hidden=64, dim_feedforward=64,\n",
    "                 dropout=0.01, positional_encoding=False):\n",
    "        super().__init__()\n",
    "        self.padding_token = padding_token\n",
    "        # TODO: Your code here.\n",
    "        self.embedding    = torch.nn.Embedding(dim_vocab, dim_hidden)\n",
    "        self.dropout      = torch.nn.Dropout(dropout)\n",
    "        self.transformer  = torch.nn.Transformer(dim_hidden, num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "                                                 dim_feedforward=dim_feedforward, batch_first=True, dropout=dropout)\n",
    "        self.predict      = torch.nn.Linear(dim_hidden, dim_vocab)\n",
    "        if positional_encoding:\n",
    "            self.pos_encoding = PositionalEncoding(dim_hidden)\n",
    "        else:\n",
    "            self.pos_encoding = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # TODO: Your code here.\n",
    "        # Combine self.embedding, self.dropout, self.transformer, self.predict\n",
    "        src_padding_mask = generate_padding_mask(src, self.padding_token)\n",
    "        tgt_padding_mask = generate_padding_mask(tgt, self.padding_token)\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt.shape[1], device=tgt.device)\n",
    "\n",
    "        src = self.pos_encoding(self.dropout(self.embedding(src)))\n",
    "        tgt = self.pos_encoding(self.dropout(self.embedding(tgt)))\n",
    "\n",
    "        out = self.transformer(src, tgt,\n",
    "                               memory_key_padding_mask=src_padding_mask, src_key_padding_mask=src_padding_mask,\n",
    "                               tgt_key_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n",
    "        return self.predict(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Construct and train a network with positional encoding<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your answer here\n",
    "net_pos = TransformerNetwork(dim_feedforward=72, positional_encoding=True)\n",
    "train(net_pos, data_loaders, epochs=100, lr=0.001, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) How does the performance of a model with positional encoding compare to a model without?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Run the trained network with input `\"123+123\"` and `\"321+321\"`.<span style=\"float:right\"> (no points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here.\n",
    "for src, tgt in [('123+123', '246'), ('321+321', '642')]:\n",
    "    print(f'For {src}={tgt}')\n",
    "    y_pred = predict(net, src, tgt)\n",
    "    print('  y_pred[0]', y_pred[0])\n",
    "    print('  encoded', torch.argmax(y_pred, dim=-1))\n",
    "    print('  tokens', decode_tokens(torch.argmax(y_pred, dim=-1)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Compare the predictions for the first element of y with what you found earlier. Can you explain what happens?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Explain in your own words why positional encoding is used in transformer networks.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Look at the learning curve. Can you suggest a way to improve the model?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h) Optional: if time permits, try to train an even better model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Predicting for new samples (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting an output given a new sample requires an appropriate search algorithm (see [d2l chapter 10.8](https://d2l.ai/chapter_recurrent-modern/beam-search.html)). Here, we will implement the simplest form: a greedy search algorithm that selects the token with the highest probability at each time step.\n",
    "\n",
    "**(a) Describe this search strategy in pseudo-code.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Implement a greedy search function to predict a sequence using `net_pos`.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_greedy(net, src, length):\n",
    "    # predict an output sequence of the given (maximum) length given input string src\n",
    "    with torch.no_grad():\n",
    "        # TODO: Your code here.\n",
    "        pass\n",
    "\n",
    "predicted_sequence = predict_greedy(net_pos, '123+123', 6)\n",
    "print(decode_tokens(predicted_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Does this search strategy give a high-quality prediction? Why, or why not?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) What alternative search strategy could we use to improve the predictions? Why would this help?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Discussion (4 points)\n",
    "\n",
    "Last week, we looked at recurrent neural networks such as the LSTM. Both recurrent neural networks and transformers work with sequences, but in recent years the transformer has become more popular than the recurrent models.\n",
    "\n",
    "**(a) An advantage of transformers over recurrent neural is that they can be faster to train. Why is that?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Does this advantage also hold when predicting outputs for new sequences? Why, or why not?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Why is positional encoding often used in transformers, but not in convolutional or recurrent neural networks?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of a recurrent neural network makes it very suitable for online predictions, such as real-time translation, because it only depends on prior inputs. You can design an architecture where the RNN produces an output token for every input token given to it, and it can produce that output without having to wait for the rest of the input.\n",
    "\n",
    "Note: 'online' means producing outputs continuously as new input comes in, as opposed to collecting a full dataset and analyzing it afterwards, it has nothing to do with the internet.\n",
    "\n",
    "**(d) How would a transformer work in an online application? Do you need to change the architecture?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end\n",
    "\n",
    "Well done! Please double check the instructions at the top before you submit your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment has 47 points.*\n",
    "<span style=\"float:right;color:#aaa;font-size:10px;\"> Version 3c66915 / 2023-10-04</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
