{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning &mdash; Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third assignment for the 2023 Deep Learning course (NWI-IMC070) of the Radboud University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Names: Luka Mucko, Luca Poli**\n",
    "\n",
    "**Group: 46**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "* Fill in your names and the name of your group.\n",
    "* Answer the questions and complete the code where necessary.\n",
    "* Keep your answers brief, one or two sentences is usually enough.\n",
    "* Re-run the whole notebook before you submit your work.\n",
    "* Save the notebook as a PDF and submit that in Brightspace together with the `.ipynb` notebook file.\n",
    "* The easiest way to make a PDF of your notebook is via File > Print Preview and then use your browser's print option to print to PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this assignment you will\n",
    "1. Experiment with convolutional neural networks\n",
    "2. Train a convolutional neural network on a speech dataset\n",
    "3. Investigate the effect of dropout and batch normalization\n",
    "4. Define and train a residual neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required software\n",
    "\n",
    "If you haven't done so already, you will need to install the following additional libraries:\n",
    "* `torch` and `torchvision` for PyTorch,\n",
    "* `d2l`, the library that comes with [Dive into deep learning](https://d2l.ai) book,\n",
    "* `python_speech_features` to compute MFCC features.\n",
    "\n",
    "All libraries can be installed with `pip install`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f379c6f35b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Fix the seed, so outputs are exactly reproducible\n",
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Convolution and receptive fields (9 points)\n",
    "\n",
    "We will first define some helper functions to plot the receptive field of a node in a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, title=None, new_figure=True):\n",
    "    if new_figure:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "    im = plt.imshow(img, interpolation='none', aspect='equal', cmap='gray')\n",
    "    ax = plt.gca();\n",
    "\n",
    "    # plot pixel numbers and grid lines\n",
    "    ax.set_xticks(np.arange(0, img.shape[1], 1))\n",
    "    ax.set_yticks(np.arange(0, img.shape[0], 1))\n",
    "    ax.set_xticklabels(np.arange(0, img.shape[1], 1))\n",
    "    ax.set_yticklabels(np.arange(0, img.shape[0], 1))\n",
    "    ax.set_xticks(np.arange(-.5, img.shape[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, img.shape[0], 1), minor=True)\n",
    "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=1.5)\n",
    "\n",
    "    # hide axis outline\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "# set all weights in the network to one,\n",
    "# all biases to zero\n",
    "def fill_weights_with_ones(network):\n",
    "    for name, param in network.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            param.data = torch.ones_like(param.data)\n",
    "        elif 'bias' in name:\n",
    "            param.data = torch.zeros_like(param.data)\n",
    "    return network\n",
    "\n",
    "def compute_receptive_field(network, input_size=(15, 15), binary=True):\n",
    "    assert isinstance(network, torch.nn.Sequential), 'This only works with torch.nn.Sequential networks.'\n",
    "    for layer in network:\n",
    "        if not isinstance(layer, (torch.nn.Conv2d, torch.nn.AvgPool2d)):\n",
    "            raise Exception('Sorry, this visualisation only works for Conv2d and AvgPool2d.')\n",
    "\n",
    "    # initialize weights to ones, biases to zeros\n",
    "    fill_weights_with_ones(network)\n",
    "\n",
    "    # find the number of input and output channels\n",
    "    input_channels = None\n",
    "    output_channels = None\n",
    "    for layer in network:\n",
    "        if isinstance(layer, torch.nn.Conv2d):\n",
    "            if input_channels is None:\n",
    "                # first convolution layer\n",
    "                input_channels = layer.in_channels\n",
    "            output_channels = layer.out_channels\n",
    "    if input_channels is None:\n",
    "        input_channels = 1\n",
    "\n",
    "    # first, we run the forward pass to compute the output shape give the input\n",
    "\n",
    "    # PyTorch expects input shape [samples, channels, rows, columns]\n",
    "    x = torch.zeros(1, input_channels, *input_size)\n",
    "    x.requires_grad = True\n",
    "\n",
    "    # forward pass: apply each layer in the network\n",
    "    y = x\n",
    "    y.retain_grad()\n",
    "    ys = [y]\n",
    "    for layer in network:\n",
    "        y = layer(y)\n",
    "        # keep track of the intermediate values so we can plot them later\n",
    "        y.retain_grad()\n",
    "        ys.append(y)\n",
    "\n",
    "    # second, we run the backward pass to compute the receptive field\n",
    "\n",
    "    # create gradient input: zeros everywhere, except for a single pixel\n",
    "    y_grad = torch.zeros_like(y)\n",
    "    # put a one somewhere in the middle of the output\n",
    "    y_grad[0, 0, (y_grad.shape[2] - 1) // 2, (y_grad.shape[3] - 1) // 2] = 1\n",
    "\n",
    "    # compute the gradients given this single one\n",
    "    y.backward(y_grad)\n",
    "\n",
    "    # receptive field is now in the gradient at each layer\n",
    "    receptive_fields = []\n",
    "    for y in ys:\n",
    "        # the gradient for this layer shows us the receptive field\n",
    "        receptive_field = y.grad\n",
    "        if binary:\n",
    "            receptive_field = receptive_field > 0\n",
    "        receptive_fields.append(receptive_field)\n",
    "    return receptive_fields\n",
    "\n",
    "def plot_receptive_field(network, input_size=(15, 15), binary=True):\n",
    "    receptive_fields = compute_receptive_field(network, input_size, binary)\n",
    "    \n",
    "    # plot the gradient at each layer\n",
    "    plt.figure(figsize=(4 * len(receptive_fields), 4))\n",
    "    for idx, receptive_field in enumerate(receptive_fields):\n",
    "        plt.subplot(1, len(receptive_fields), idx + 1)\n",
    "        # the last element of ys contains the output of the network\n",
    "        if idx == len(receptive_fields) - 1:\n",
    "            plot_title = 'output (%dx%d)' % (receptive_field.shape[2], receptive_field.shape[3])\n",
    "        else:\n",
    "            plot_title = 'layer %d input (%dx%d)' % (idx, receptive_field.shape[2], receptive_field.shape[3])\n",
    "        # plot the image with the receptive field (sample 0, channel 0)\n",
    "        show_image(receptive_field[0, 0], new_figure=False, title=plot_title)\n",
    "        if not binary:\n",
    "            plt.colorbar(fraction=0.047 * receptive_field.shape[0] / receptive_field.shape[1])\n",
    "\n",
    "def receptive_field_size(network, input_size=(15, 15), binary=True):\n",
    "    receptive_fields = compute_receptive_field(network, input_size, binary)\n",
    "    return torch.count_nonzero(torch.flatten(receptive_fields[0][0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these functions, we can define a network and plot the receptive field of a pixel in the output.\n",
    "\n",
    "**(a) Run the code to define a network with one 3Ã—3 convolution layer and plot the images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3)),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read these images as follows:\n",
    "* On the left, you see the input size of the network (here: 15 x 15 pixels) and the receptive field for one pixel in the output.\n",
    "* On the right, you see the output size of the network (here: 13 x 13 pixels).\n",
    "\n",
    "To visualize the receptive field of this network, we used the following procedure:\n",
    "* We selected one pixel of the output (shown as the white pixel in the center in the image on the right).\n",
    "* We computed the gradient for this pixel and plotted the gradient with respect to the input (the image on the left).\n",
    "* This shows you the receptive field of the network: the output for the pixel we selected depends on these 9 pixels in the input.\n",
    "\n",
    "**(b) Use this method to plot the receptive field of a pixel in the output of a convolution layer with a kernel size of 5Ã—5.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Plot the receptive field of a 5x5 convolution.\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(5, 5)),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the result, you will see that two things have changed: the receptive field and the output size.\n",
    "\n",
    "**(c) How do the receptive field size and the output size depend on the kernel size? Give a formula.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Receptive field size R given kernel size K and stride S \\\n",
    "R=(K-1)S+1\n",
    "\n",
    "\n",
    "Output size O given input size I, padding P and stride S: \\\n",
    "O = $\\frac{I-K+2P}{S}+1$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Counting the number of parameters\n",
    "\n",
    "In the previous question, you saw how the receptive fields of a 3x3 convolution differs from a 5x5 kernel convolution. But this is not the only difference: there is also a difference in the number of parameters in the network.\n",
    "\n",
    "We can count the number of parameters in the network by computing the number of elements (e.g., the weights and biases in a convolution kernel) in the parameter list of the PyTorch network.\n",
    "\n",
    "We'll define a small helper function to do this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_parameter_count(network):\n",
    "    # sum the number of elements in each parameter of the network\n",
    "    count = sum([param.data.numel() for param in network.parameters()])\n",
    "    print('%d parameters' % count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(d) Use the function to count the number of parameters for a 3x3 convolution.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3)),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(e) Do the same to count the number of parameters for a 5x5 convolution.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO count the number of parameters of a 5x5 convolution\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(5, 5)),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(f) Explain the results by showing how to _compute_ the number of parameters for the 3x3 and 5x5 convolutions.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of parameters of convolutional layer of size K with 1 in/out channel is $k \\times k + 1$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For these computations we used convolution layers with one input and one output channel.\n",
    "\n",
    "We can also compute the results for a layer with a different number of channels.\n",
    "\n",
    "**(g) Define a network with a 5x5 convolution, 2 input channels and 3 output channels. Print the number of parameters.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO count the number of parameters of a 5x5 convolution with 2 input channels and 3 output channels\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(2, 3, kernel_size=(5, 5)),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(h) Show how to compute the number of parameters for this case.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "in = 2 \\\n",
    "out = 3 \\\n",
    "k = 5 \\\n",
    "n_weights = (in\\*out\\*k\\*k)+out*1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preserving the size of the input image\n",
    "\n",
    "The PyTorch documentation for [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) describes the parameters that you can use to define a convolutional layer. We will explore some of those parameters in the next questions.\n",
    "\n",
    "In the previous plot, you may have noticed that the output (13x13 pixels) was slightly smaller than the input (15x15 pixels).\n",
    "\n",
    "**(i) Define a network with a single 3x3 convolutional layer that produces an output that has the same size as the input.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Use 1 input and 1 output channel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO Define a network with a 3Ã—3 kernel size that takes a 15Ã—15 input image\n",
    "#      and produces a 15Ã—15 output image.\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3), stride=1, padding=1),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(j) Define a network with a single 5x5 convolutional layer that preserves the input size.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO Define a network with a 5Ã—5 kernel size that takes a 15Ã—15 input image\n",
    "#      and produces a 15Ã—15 output image.\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(5, 5), stride=1, padding=2),\n",
    ")\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Play around with some other values to see how this parameter behaves."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiple layers\n",
    "\n",
    "As you have just seen, one way to increase the size of the receptive field is to use a larger convolution kernel. But another way is to use more than one convolution layer.\n",
    "\n",
    "**(k) Define a network with two 3x3 convolutions, preserving the image size. Show the receptive field and the number of parameters.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "For this visualisation, do not use any activation functions, and use 1 channel everywhere."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO define a network with two 3x3 convolutions\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3)),\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3))\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we now have two layers, the visualization shows an extra image. From right to left, we have:\n",
    "* Right: the output size and a single active pixel.\n",
    "* Middle: the receptive field for the single output pixel between the first and second convolution.\n",
    "* Left: the receptive field for the single output pixel in the input image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have now tried two ways to increase the receptive field size: increasing the kernel size, and using multiple layers.\n",
    "\n",
    "**(l) Compare the number of parameters required by the two options. Which one is more parameter-efficient?<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Double 3x3 convolution has 20 parameters while 5x5 convolution has 26 parameters so 3x3 is more parameter-efficient."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Variations on convolution (8 points)\n",
    "\n",
    "### Pooling\n",
    "\n",
    "We can also increase the size of the receptive field by using a pooling layer.\n",
    "\n",
    "**(a) Construct a network with a 3x3 convolution (preserving the input size) followed by a 2x2 average pooling. Plot the receptive field and print the number of parameters.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Use 1 input and 1 output channel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO define a network with two 3x3 convolutions\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3), padding=1),\n",
    "    torch.nn.AvgPool2d(kernel_size=(2, 2))\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(b) Explain the number of parameters in this convolution + pooling network.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 10 parameters, which came from the Conv2d layer (1x1x3x3 +1 bias). The pooling layer does not have any learnable parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dilation\n",
    "\n",
    "A third option to increase the receptive field is _dilation_.\n",
    "\n",
    "**(c) Define a network with 3x3 convolution with dilation that preserves the input size.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO define a network with one 3x3 convolution with dilation\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3), padding=2, dilation=2),\n",
    ")\n",
    "# the output should also be 15x15 pixels\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(15, 15))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(d) Explain how dilation affects the receptive field.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With dilation each pixel in the receptive field is now 2 pixels apart instead of 1. So the receptive field increases without increasing the number of parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using strides\n",
    "\n",
    "By default, convolution layers use a stride of 1.\n",
    "\n",
    "**(e) Change the network to use a stride of 2 and plot the result.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO increase the stride to 2\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 1, kernel_size=(3, 3), padding=(1, 1), stride=(2, 2)),\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(14, 14))\n",
    "print_parameter_count(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(f) Explain the new output size and compare the result with that of pooling.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With stride 2 the output size is 7x7, because the stride cause the filter to skip some pixel (so the output dimension is halved). This is the same as the pooling layer, but in this case we have learnable parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(g) Explain how the stride affects the receptive field of this single convolution layer.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The stride causes the filter to skip some pixel, the receptive field dimension is the same, but the receptive field in the output are more sparsely distributed (by a factor of 2)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(h) Explain the number of parameters for this network.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The stride does not affect the number of parameters, so we still have 10 parameters. But it can effect the number of parameters in future layers (because the output size is smaller)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Combining layers (7 points)\n",
    "\n",
    "As you have seen, there are multiple ways to increase the receptive field. You can make interesting combinations by stacking multiple layers.\n",
    "\n",
    "Let's try a few ways to make networks with a large receptive field. For each of the questions in this section:\n",
    "\n",
    "* Create a network where a pixel in the output has a 9x9 receptive field.\n",
    "* Use 3 input channels and 3 output channels in every layer.\n",
    "* In convolution layers, try to preserve the input size as much as possible.\n",
    "\n",
    "**(a) Make a network with a single convolution that satisfies the above conditions.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(9,9), padding=4)\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(14, 14))\n",
    "print_parameter_count(net)\n",
    "assert receptive_field_size(net) == 9*9, \"Receptive field of output pixel should be a 9x9 square\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Many popular network architectures use a sequence of 3x3 convolutions.\n",
    "\n",
    "**(b) Use only 3x3 convolutions.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3),padding=1),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3),padding=1),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3),padding=1),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3),padding=1)\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(14, 14))\n",
    "print_parameter_count(net)\n",
    "assert receptive_field_size(net) == 9*9, \"Receptive field of output pixel should be a 9x9 square\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(c) Use a 2x2 average pooling layer in combination with one or more 3x3 convolutions. (Use any kernel size)<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3), padding=1),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(2,2), padding=2),\n",
    "    torch.nn.AvgPool2d(kernel_size=(2,2)),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3), padding=4),\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(14, 14))\n",
    "print_parameter_count(net)\n",
    "assert receptive_field_size(net) == 9*9, \"Receptive field of output pixel should be a 9x9 square\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(d) Copy the previous convolution + pooling network and replace the pooling layer with a strided convolution layer.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3), padding=1),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(2,2), padding=2),\n",
    "    torch.nn.Conv2d(3,3, kernel_size=(2,2), stride=2),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3), padding=4),\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(14, 14))\n",
    "print_parameter_count(net)\n",
    "assert receptive_field_size(net) == 9*9, \"Receptive field of output pixel should be a 9x9 square\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(e) Construct a network with exactly two 3x3 convolutions. Use dilation to get a receptive field of 9x9 pixels.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3), padding=1, dilation=3),\n",
    "    torch.nn.Conv2d(3, 3, kernel_size=(3,3), padding=3)\n",
    ")\n",
    "print(net)\n",
    "plot_receptive_field(net, input_size=(14, 14))\n",
    "print_parameter_count(net)\n",
    "assert receptive_field_size(net) == 9*9, \"Receptive field of output pixel should be a 9x9 square\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(f) For each of the methods, list the number of layers, the number of parameters, and the size of the output of the network:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Method                    | Layers | Parameters | Output size |\n",
    "|---------------------------|--------|------------|-------------|\n",
    "| One 9x9 convolution       |    1   |     732    |    14x14    | \n",
    "| Many 3x3 convolutions     |    4   |     336    |    14x14    |\n",
    "| With pooling              |    4   |     207    |    14x14    |\n",
    "| With strided convolution  |    4   |     246    |    14x14    |\n",
    "| With dilation             |    2   |     168    |    14x14    |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(g) Compare the methods in terms of the number of parameters.<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One 9x9 convolution has the most parameters. \\\n",
    "4 3x3 convolutions have only 336 parameters. \\\n",
    "Pooling layer doesn't have parameters and for the sake of constraints we had to use a 2x2 convolution so the number of parameters is even lower than 4x(3x3). \\\n",
    "We replaced the pooling operator by a 2x2 convolution which gave us a larger number of parameters than the pooling one. \\\n",
    "Dilation doesn't add new parameters so we have just 2x(3x3) convolutions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(h) Compare the methods in terms of the output size. How much downsampling do they do?<span style=\"float:right\"> (1 point)</span>**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One convolutional layer of k$\\times$k reduces the 2d image by (k-1) in both dimensions. \\\n",
    "2$\\times$2 pooling reduces the image size n to $\\lceil\\frac{n}{2}\\rceil$ \\\n",
    "Higher stride reduces the output size (O=(I-K+2P)/S + 1) \\\n",
    "Dilation does not affect the output size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 Padding in very deep networks (2 points)\n",
    "\n",
    "Without padding, the output of a convolution is smaller than the input. This limits the depth of your network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(a) How often can you apply a 3x3 convolution to a 15x15 input image?**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the maximum number of layers\n",
    "number_of_times = 25\n",
    "\n",
    "# create a 15x15 input\n",
    "x = torch.zeros(1, 1, 15, 15)\n",
    "print('input size: %dx%d' % (x.shape[2], x.shape[3]))\n",
    "\n",
    "# create a 3x3 convolution\n",
    "conv = torch.nn.Conv2d(1, 1, kernel_size=(3, 3))\n",
    "\n",
    "for n in range(number_of_times):\n",
    "    # apply another convolution\n",
    "    x = conv(x)\n",
    "    print('layer %d, output size: %dx%d' % (n + 1, x.shape[2], x.shape[3]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Earlier in this assignment, you have used padding to address this problem. This seems ideal.\n",
    "\n",
    "**(b) Copy the previous code, add some padding, and show that we can now have an infinite number of layers.**\n",
    "\n",
    "(We are computer scientists and not mathematicians, so for the purpose of this question we'll consider 'infinite' to be equal to 25.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the maximum number of layers\n",
    "number_of_times = 25\n",
    "\n",
    "# create a 15x15 input\n",
    "x = torch.zeros(1, 1, 15, 15)\n",
    "print('input size: %dx%d' % (x.shape[2], x.shape[3]))\n",
    "\n",
    "# create a 3x3 convolution\n",
    "conv = torch.nn.Conv2d(1, 1, kernel_size=(3, 3), padding=(1, 1))\n",
    "\n",
    "for n in range(number_of_times):\n",
    "    # apply another convolution\n",
    "    x = conv(x)\n",
    "    print('layer %d, output size: %dx%d' % (n + 1, x.shape[2], x.shape[3]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Does it really work like this? Have a look at the following experiment.**\n",
    "\n",
    "* We simulate a convolution network with 25 convolution layers, with 3x3 kernels and the right amount of padding.\n",
    "* We set the weights to 1/9 (so that the sum of the 3x3 kernel is equal to 1) and set the bias to zero.\n",
    "* We give this network a 15x15-pixel input filled with ones.\n",
    "* We plot the output of layers 5, 10, 15, 20, and 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a 15x15 input filled with ones\n",
    "x = torch.ones(1, 1, 15, 15)\n",
    "\n",
    "# create a 3x3 convolution\n",
    "conv = torch.nn.Conv2d(1, 1, kernel_size=(3, 3), padding=(1, 1))\n",
    "\n",
    "# set weights to 1/9 (= sum to one), bias to zero\n",
    "conv.weight.data = torch.ones_like(conv.weight.data) / 9\n",
    "conv.bias.data = torch.zeros_like(conv.bias.data)\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "for n in range(1, 26):\n",
    "    # apply another convolution\n",
    "    x = conv(x)\n",
    "    # print('layer %d, output size: %dx%d' % (n + 1, x.shape[2], x.shape[3]))\n",
    "    if n % 5 == 0:\n",
    "        plt.subplot(1, 5, n // 5)\n",
    "        plt.imshow(x[0, 0].detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('layer %d' % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Explain the pattern that we see in the output of the final layers. How does this happen, and what does this mean for our very deep networks?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output we can see that the image at each iteration become more blurred, and the pixels become more similar to each other. This happens because the convolution operation is working like a simple averaging filter (caused by the weight with values 1/9). So ad each layer the network spread and smooth the input image. So this repeated application of the same filter is useless, and can cause the lost of informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Spoken digits dataset (4 points)\n",
    "\n",
    "Time for some practical experiments. The d2l book uses a dataset of images as a running example (FashionMNIST). In this assignment we will investigate CNNs in a completely different domain: speech recognition.\n",
    "\n",
    "The dataset we use is the free spoken digits dataset, which can be found on https://github.com/Jakobovski/free-spoken-digit-dataset. This dataset consists of the digits 0 to 9, spoken by different speakers. The data comes as .wav files.\n",
    "\n",
    "**(a) Use the commands below (or a similar tool) to download the dataset. You can also use `git clone` to clone the repository mentioned above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir -p free-spoken-digit-dataset\n",
    "#! wget -O - https://github.com/Jakobovski/free-spoken-digit-dataset/archive/refs/heads/master.tar.gz | tar xzv -C free-spoken-digit-dataset --strip-components=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to load the data. We pad/truncate each sample to the same length.\n",
    "The raw audio is usually stored in 16 bit integers, with a range -32768 to 32767, where 0 represents no signal. Before using the data, it should be normalized. A common approach is to make sure that the data is between 0 and 1, between -1 and 1, or zero-mean unit-variance.  Not all of these work well on this data, so later on, if your\n",
    "network doesn't seem to learn anything: try a different method to see if that works better.\n",
    "\n",
    "**(b) Update the below code to normalize the data to a reasonable range.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 8000\n",
    "def load_waveform(file, size = 6000):\n",
    "    samplerate, waveform = wavfile.read(file)\n",
    "    # Take first 6000 samples from waveform. With a samplerate of 8000 that corresponds to 3/4 second\n",
    "    # Pad with 0s if the file is shorter\n",
    "    waveform = np.pad(waveform,(0,size))[0:size]\n",
    "    # Normalize waveform\n",
    "    waveform = (waveform + 32768) / (32768 + 32767)  # normalized between 0 and 1\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads all .wav files in a directory, and makes it available in a pytorch dataset.\n",
    "\n",
    "**(c) Load the data into a variable `data`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpokenDigits(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        digits_x = []\n",
    "        digits_y = []\n",
    "        for file in os.listdir(data_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                waveform = load_waveform(os.path.join(data_dir, file))\n",
    "                label = int(file[0])\n",
    "                digits_x.append(waveform)\n",
    "                digits_y.append(label)\n",
    "        # convert to torch tensors\n",
    "        self.x = torch.from_numpy(np.array(digits_x, dtype=np.float32))\n",
    "        # add an extra dimension to represent the \"channels\" (we start with 1 channel of data)\n",
    "        self.x = self.x.unsqueeze(1)\n",
    "        self.y = torch.from_numpy(np.array(digits_y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "data = SpokenDigits('free-spoken-digit-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Describe the dataset: how many samples are there, how many features does each sample have? How many classes are there?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.x.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of samples: \", data.x.size()[0])\n",
    "print(\"Number of features: \", data.x.size()[2])\n",
    "print(\"Number of classes:\", data.y.unique().size()[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is code to play samples from the dataset to give you an idea what it \"looks\" like.\n",
    "\n",
    "Note: If this step doesn't work in your notebook, then you can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "def play(sample):\n",
    "    print(f'Label: {sample[1]}')\n",
    "    return Audio(sample[0][0].numpy(), rate=samplerate)\n",
    "play(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, we split the dataset into a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 2/3\n",
    "train_count = int(len(data) * train_prop)\n",
    "train, test = torch.utils.data.random_split(data, [train_count, len(data) - train_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses 2/3 of the data for training.\n",
    "\n",
    "**(e) Discuss an advantage and disadvantage of using more of the data for training.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using more data for training we can build a more complex model (with more parameters) and we can avoid overfitting. But we have less data for testing, so we can have a less accurate evaluation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we split the data into batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {'batch_size': 32}\n",
    "train_iter = torch.utils.data.DataLoader(train, **data_params)\n",
    "test_iter  = torch.utils.data.DataLoader(test,  **data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 One-dimensional convolutional neural network (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a network architecture. We will use a combination of convolutional layers and pooling.\n",
    "Note that we use 1d convolution and pooling here, instead of the 2d operations used for images.\n",
    "\n",
    "**(a) Complete the network architecture, look at the d2l book [chapter 7](http://d2l.ai/chapter_convolutional-neural-networks/index.html) and [chapter 8](http://d2l.ai/chapter_convolutional-modern/index.html) for examples.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net():\n",
    "    return torch.nn.Sequential(\n",
    "        nn.Conv1d(1, 4, kernel_size=5), nn.ReLU(),\n",
    "        nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        # TODO: Add three more convolutional layers, ReLU layers and pooling layers;\n",
    "        #       doubling the number of channels each time\n",
    "        # TODO: Your code here.\n",
    "        nn.Conv1d(4, 8, kernel_size=5), nn.ReLU(),\n",
    "        nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        nn.Conv1d(8, 16, kernel_size=5), nn.ReLU(),\n",
    "        nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        nn.Conv1d(16, 32, kernel_size=5), nn.ReLU(),\n",
    "        nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(11872, 128), nn.ReLU(),\n",
    "        nn.Linear(128, 64), nn.ReLU(),\n",
    "        nn.Linear(64, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) The first fully connected layer has input dimension 11872, where does that number come from?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here.\n",
    "\n",
    "Hint: think about how (valid) convolutional layers and pooling layers with stride affect the size of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) How many parameters are there in the model? I.e. the total number of weights and biases.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the number of parameters\n",
    "print_parameter_count(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Suppose that instead of using convolutions, we had used only fully connected layers, while keeping the number of features on each hidden layer the same. How many parameters would be needed in that case approximately?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FashionMNIST dataset used in the book has 60000 training examples. How large is our training set? How would the difference affect the number of epochs that we need? Compare to [chapter 7.6](http://d2l.ai/chapter_convolutional-neural-networks/lenet.html) and [chapter 8.1](http://d2l.ai/chapter_convolutional-modern/alexnet.html) of the book.\n",
    "\n",
    "**(e) How many epochs do you think are needed?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.01, 10 # TODO: change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the code from (a previous edition of) the d2l book to train the network.\n",
    "In particular, the `train` function, defined in [chapter 7.6](http://d2l.ai/chapter_convolutional-neural-networks/lenet.html#training). This function is reproduced below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, lr, device = d2l.try_gpu()):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device, torch.long)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Now train the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(build_net(), train_iter, test_iter, num_epochs=75, lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Did the training converge?<span style=\"float:right\"> (2 point)</span>**\n",
    "\n",
    "**If the training has not converged, maybe you need to change the number of epochs and/or the learning rate.**\n",
    "\n",
    "Hint: This is a non-trivial problem, so your network might take some time to\n",
    "learn. Don't give up too quickly, it might take 50-100 epochs before you\n",
    "see any significant changes in the loss curves.\n",
    "\n",
    "TODO: Document the runs that you have performed and thir results in the table below.\n",
    "\n",
    "| Experiment                | epochs | lr     | train accuracy | test accuracy | converged? |\n",
    "|---------------------------|--------|--------|----------------|---------------|------------|\n",
    "| experiment 1              | 1234   | 1234   |                |               |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Questions and evaluation (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Does the network look like it is overfitting or underfitting? Explain how see this.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Is what we have here a good classifier? Could it be used in a realistic application? Motivate your answer.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: discuss your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Do you think there is enough training data compared to the dimensions of the data and the number of parameters? Motivate your answer.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) How could the classifier be improved? Give at least 2 suggestions.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) The free spoken digits datasets has recordings from several different speakers. Is the test set accuracy a good measure of how well the trained network would perform for recognizing digits spoken by a new, unknown speaker? And if not, how could that be tested instead?<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Variations (8 points)\n",
    "\n",
    "One way in which the training might be improved is with dropout or with batch normalization.\n",
    "\n",
    "**(a) Make a copy of the network architecture from 3.6a below, and add dropout.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Hint: see [chapter 8.1](http://d2l.ai/chapter_convolutional-modern/alexnet.html#architecture) for an example that uses dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net_dropout():\n",
    "    return ...  # TODO: your network here\n",
    "\n",
    "train(build_net_dropout(), train_iter, test_iter, num_epochs=200, lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) How does dropout change the results? Does this match what you saw on the simple network last week?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Make a copy of the original network architecture, and add batch normalization to all convolutional and linear layers.<span style=\"float:right\"> (1 point)</span>**\n",
    "\n",
    "Hint: see [chapter 8.5](http://d2l.ai/chapter_convolutional-modern/batch-norm.html#concise-implementation) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net_batchnorm():\n",
    "    return ...  # TODO: your network here\n",
    "\n",
    "train(build_net_batchnorm(), train_iter, test_iter, num_epochs=15, lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) How does batch normalization change the results? Does this match what you saw on the simple network last week?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual network\n",
    "\n",
    "We can also try to use a residual network. The book has code for a 2d resnet in [Chapter 8.6](http://d2l.ai/chapter_convolutional-modern/resnet.html).\n",
    "\n",
    "**(e) Copy the `Residual` module here, and adapt it for 1d convolutions. Use a kernel size of 5 for the convolution layers.<span style=\"float:right\"> (2 points)</span>**\n",
    "\n",
    "Use residual blocks each containing two convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Residual class here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Make a copy of the network architecture from 3.6a, and replace the convolutions with residual blocks.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet():\n",
    "    return ...  # TODO: your network here\n",
    "\n",
    "# TODO train(resnet, train_iter, test_iter, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) How do residual connections change the results?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Feature extraction (5 points)\n",
    "\n",
    "Given enough training data a deep neural network can learn to extract features from raw data like audio and images. However, in some cases it is still necessary to do manual feature extraction, in particular when working with smaller datasets like this one. For speech recognition, a popular class of features are [MFCCs](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum).\n",
    "\n",
    "Here is code to extract these features. You will need to install the `python_speech_features` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "\n",
    "def load_waveform_mfcc(file, size = 6000):\n",
    "    samplerate, waveform = wavfile.read(file)\n",
    "    waveform = np.pad(waveform,(0,size))[0:size] / 32768\n",
    "    return np.transpose(mfcc(waveform, samplerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Implement a variation of the dataset that uses these features.<span style=\"float:right\"> (2 points)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpokenDigitsMFCC(torch.utils.data.Dataset):\n",
    "    # TODO: Your code here.\n",
    "    ...\n",
    "\n",
    "data_mfcc = SpokenDigitsMFCC(data_dir) # TODO: your data directory here\n",
    "train_count_mfcc = int(len(data_mfcc) * train_prop)\n",
    "train_mfcc, test_mfcc = torch.utils.data.random_split(data_mfcc, [train_count_mfcc, len(data_mfcc)-train_count_mfcc])\n",
    "train_iter_mfcc = torch.utils.data.DataLoader(train_mfcc, **data_params)\n",
    "test_iter_mfcc  = torch.utils.data.DataLoader(test_mfcc,  **data_params)\n",
    "\n",
    "assert next(iter(train_iter_mfcc))[0].shape == torch.Size([data_params['batch_size'],13,74]), \"There is something wrong with the SpokenDigitsMFCC dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MFCC features will have 13 channels instead of 1 (the `unsqueeze` operation is not needed). \n",
    "\n",
    "**(b) Inspect the shape of the data, and define a new network architecture that accepts data with this shape.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net_mfcc():\n",
    "    # TODO: Your code here.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Train the network with the MFCC features.<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) What would be needed to get a fully neural network approach to work as well as MFCC features?<span style=\"float:right\"> (1 point)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end\n",
    "\n",
    "Well done! Please double check the instructions at the top before you submit your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment has 57 points.*\n",
    "<span style=\"float:right;color:#aaa;font-size:10px;\"> Version 6717cb8 / 2023-09-15</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
